{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import catboost\n",
    "import re\n",
    "import optuna\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer,\n",
    "                                   OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "col_names = []\n",
    "with open('../data/Faults27x7_var','r') as f:\n",
    "    for line in f:\n",
    "        col_names.append(line.strip())\n",
    "        \n",
    "train_org = pd.read_csv('../data/train.csv')\n",
    "test_org = pd.read_csv('../data/test.csv')\n",
    "org_data = pd.read_csv('../data/Faults.NNA', delimiter='\\s', engine='python', names=col_names)\n",
    "\n",
    "X = train_org.drop(['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps','Other_Faults'], axis=1)\n",
    "pastry = train_org['Pastry'].copy()\n",
    "z_scratch = train_org['Z_Scratch'].copy()\n",
    "k_scatch = train_org['K_Scatch'].copy()\n",
    "stains = train_org['Stains'].copy()\n",
    "dirtiness = train_org['Dirtiness'].copy()\n",
    "bumps = train_org['Bumps'].copy()\n",
    "other_faults = train_org['Other_Faults'].copy()\n",
    "\n",
    "ys = [pastry, z_scratch, k_scatch, stains, dirtiness, bumps, other_faults]\n",
    "y_names = ['pastry', 'z_scratch', 'k_scatch', 'stains', 'dirtiness', 'bumps', 'other_faults']\n",
    "\n",
    "class KMeansTransformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=0)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        self.kmeans.fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        labels = self.kmeans.predict(X)\n",
    "        return np.c_[X, labels]\n",
    "    \n",
    "class PCA_Transformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=self.n_components, random_state=0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.pca.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        cols = self.pca.transform(X)\n",
    "        return np.c_[X, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = {}\n",
    "    for i in range(0,9):\n",
    "        if i ==1:\n",
    "            continue\n",
    "        y_params_dict[y_nm][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'z_scratch': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'k_scatch': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'stains': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'dirtiness': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'bumps': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None},\n",
       " 'other_faults': {0: None,\n",
       "  2: None,\n",
       "  3: None,\n",
       "  4: None,\n",
       "  5: None,\n",
       "  6: None,\n",
       "  7: None,\n",
       "  8: None}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate(range(1,9)):\n",
    "        \n",
    "        if n == 0:\n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1)        \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            score_without_hpt = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            \n",
    "            \n",
    "            def objective_lgb(trial):\n",
    "    \n",
    "                cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "                params = dict(\n",
    "                    n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                    max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                    num_leaves = trial.suggest_int('num_leaves',2,128),\n",
    "                    learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                    min_child_samples = trial.suggest_int('min_child_samples',2,500),\n",
    "                    min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                    subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                    colsample_bytree = trial.suggest_float('colsample_bylevel',0.33,0.7),\n",
    "                    reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                    reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "                )\n",
    "                \n",
    "                lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "                \n",
    "                pipe = Pipeline(\n",
    "                    steps = [\n",
    "                        ('scaler', StandardScaler()),\n",
    "                        ('model', lgbc)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "                return score\n",
    "            \n",
    "            study_lgb = optuna.create_study(direction='maximize')\n",
    "            \n",
    "            study_lgb.optimize(objective_lgb, n_trials=100, n_jobs=-1, show_progress_bar=True)\n",
    "            \n",
    "            best_params = study_lgb.best_params\n",
    "            y_params_dict[yn][0] = best_params\n",
    "            \n",
    "            best_score = study_lgb.best_value\n",
    "            y_scores.append((yn,f'score_without_hpt: {score_without_hpt}', f'score_after_hpt: {best_score}'))\n",
    "            \n",
    "            time.sleep(5)\n",
    "            clear_output()\n",
    "            continue\n",
    "            \n",
    "        lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1)        \n",
    "        pipe = Pipeline(\n",
    "            steps = [\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                ('model', lgbc)\n",
    "            ]\n",
    "        )\n",
    "        score_without_hpt = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "        \n",
    "        def objective_lgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                num_leaves = trial.suggest_int('num_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                min_child_samples = trial.suggest_int('min_child_samples',2,500),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bylevel',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_lgb, n_trials=100, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores.append((yn,f'score_without_hpt(n_clusters={i}): {score_without_hpt}', f'score_after_hpt(n_clusters={i}): {best_score}'))\n",
    "        \n",
    "        time.sleep(5)\n",
    "        clear_output()\n",
    "        \n",
    "        with open('results.txt', 'w') as file:\n",
    "            for tup in y_scores:\n",
    "                file.write(f'{tup[0]}, {tup[1]}, {tup[2]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
