{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import catboost\n",
    "import re\n",
    "import optuna\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import main\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer,\n",
    "                                   OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "col_names = []\n",
    "with open('../data/Faults27x7_var','r') as f:\n",
    "    for line in f:\n",
    "        col_names.append(line.strip())\n",
    "        \n",
    "train_org = pd.read_csv('../data/train.csv')\n",
    "test_org = pd.read_csv('../data/test.csv')\n",
    "org_data = pd.read_csv('../data/Faults.NNA', delimiter='\\s', engine='python', names=col_names)\n",
    "\n",
    "X = train_org.drop(['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps','Other_Faults'], axis=1)\n",
    "pastry = train_org['Pastry'].copy()\n",
    "z_scratch = train_org['Z_Scratch'].copy()\n",
    "k_scatch = train_org['K_Scatch'].copy()\n",
    "stains = train_org['Stains'].copy()\n",
    "dirtiness = train_org['Dirtiness'].copy()\n",
    "bumps = train_org['Bumps'].copy()\n",
    "other_faults = train_org['Other_Faults'].copy()\n",
    "\n",
    "ys = [pastry, z_scratch, k_scatch, stains, dirtiness, bumps, other_faults]\n",
    "y_names = ['pastry', 'z_scratch', 'k_scatch', 'stains', 'dirtiness', 'bumps', 'other_faults']\n",
    "\n",
    "class KMeansTransformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=0)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        self.kmeans.fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        labels = self.kmeans.predict(X)\n",
    "        return np.c_[X, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,y_name in zip(ys,y_names):\n",
    "    \n",
    "    print(f'trial: {y_name}')\n",
    "    \n",
    "    def objective_lgb(trial):\n",
    "    \n",
    "        cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        params = dict(\n",
    "            n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "            max_depth = trial.suggest_int('max_depth',2,64),\n",
    "            num_leaves = trial.suggest_int('num_leaves',2,128),\n",
    "            learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "            min_child_samples = trial.suggest_int('min_child_samples',2,500),\n",
    "            min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "            subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "            colsample_bytree = trial.suggest_float('colsample_bylevel',0.33,0.7),\n",
    "            reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "            reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "        )\n",
    "        \n",
    "        lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "        \n",
    "        pipe = Pipeline(\n",
    "            steps = [\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', lgbc)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "        return score\n",
    "    \n",
    "    study_lgb = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "    \n",
    "    best_params = study_lgb.best_params\n",
    "    y_params_dict[y_name] = best_params\n",
    "    \n",
    "    best_score = study_lgb.best_value\n",
    "    y_scores[y_name] = best_score\n",
    "    \n",
    "    time.sleep(2)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'lgbc vanilla with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = {}\n",
    "    for i in [4,5,7]:\n",
    "        if i ==1:\n",
    "            continue\n",
    "        y_params_dict[y_nm][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}\n",
    "for yns in y_names:\n",
    "    y_scores[yns] = {}\n",
    "    for n in [4,5,7]:\n",
    "        y_scores[yns][n] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate([4,5,7]):\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_lgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(2)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'lgbc experiment with varying n_clusters(4,5,7) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate([2,3]):\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_lgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(2)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'lgbc experiment with varying n_clusters(2,3) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': {'n_estimators': 414,\n",
       "  'max_depth': 5,\n",
       "  'num_leaves': 51,\n",
       "  'learning_rate': 0.027772778201643363,\n",
       "  'min_child_samples': 163,\n",
       "  'min_child_weight': 6.83071327201467,\n",
       "  'subsample': 0.49696742935005617,\n",
       "  'colsample_bylevel': 0.35120262401687735,\n",
       "  'reg_alpha': 0.09765235819012545,\n",
       "  'reg_lambda': 0.05441956449748974},\n",
       " 'z_scratch': {'n_estimators': 247,\n",
       "  'max_depth': 13,\n",
       "  'num_leaves': 26,\n",
       "  'learning_rate': 0.023970308041410808,\n",
       "  'min_child_samples': 229,\n",
       "  'min_child_weight': 7.367478870340577,\n",
       "  'subsample': 0.39095982111246597,\n",
       "  'colsample_bylevel': 0.34924153428375315,\n",
       "  'reg_alpha': 0.05387841564588599,\n",
       "  'reg_lambda': 0.06614746132682563},\n",
       " 'k_scatch': {'n_estimators': 404,\n",
       "  'max_depth': 11,\n",
       "  'num_leaves': 14,\n",
       "  'learning_rate': 0.01981017812667226,\n",
       "  'min_child_samples': 306,\n",
       "  'min_child_weight': 1.0908593258138115,\n",
       "  'subsample': 0.5677335874920294,\n",
       "  'colsample_bylevel': 0.34897570166413927,\n",
       "  'reg_alpha': 0.08436824936832184,\n",
       "  'reg_lambda': 0.09195850550160545},\n",
       " 'stains': {'n_estimators': 322,\n",
       "  'max_depth': 5,\n",
       "  'num_leaves': 92,\n",
       "  'learning_rate': 0.029766092063977827,\n",
       "  'min_child_samples': 151,\n",
       "  'min_child_weight': 0.1205682836029196,\n",
       "  'subsample': 0.5907484621716648,\n",
       "  'colsample_bylevel': 0.33879016317263094,\n",
       "  'reg_alpha': 0.07507008418960204,\n",
       "  'reg_lambda': 0.09811102241575788},\n",
       " 'dirtiness': {'n_estimators': 337,\n",
       "  'max_depth': 7,\n",
       "  'num_leaves': 115,\n",
       "  'learning_rate': 0.025712309615029738,\n",
       "  'min_child_samples': 210,\n",
       "  'min_child_weight': 5.236174364070404,\n",
       "  'subsample': 0.4960896732608535,\n",
       "  'colsample_bylevel': 0.3375547484930559,\n",
       "  'reg_alpha': 0.007527718495031351,\n",
       "  'reg_lambda': 0.05941735936004544},\n",
       " 'bumps': {'n_estimators': 440,\n",
       "  'max_depth': 28,\n",
       "  'num_leaves': 19,\n",
       "  'learning_rate': 0.016607107107451977,\n",
       "  'min_child_samples': 207,\n",
       "  'min_child_weight': 4.404618505190154,\n",
       "  'subsample': 0.7646085514405074,\n",
       "  'colsample_bylevel': 0.3382522020165657,\n",
       "  'reg_alpha': 0.0475692589665815,\n",
       "  'reg_lambda': 0.09784427481545817},\n",
       " 'other_faults': {'n_estimators': 311,\n",
       "  'max_depth': 7,\n",
       "  'num_leaves': 125,\n",
       "  'learning_rate': 0.025912480559769024,\n",
       "  'min_child_samples': 197,\n",
       "  'min_child_weight': 9.117678137013794,\n",
       "  'subsample': 0.4357549608630758,\n",
       "  'colsample_bylevel': 0.3479605203770583,\n",
       "  'reg_alpha': 0.08718267073654712,\n",
       "  'reg_lambda': 0.0991755655443088}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 247,\n",
       " 'max_depth': 13,\n",
       " 'num_leaves': 26,\n",
       " 'learning_rate': 0.023970308041410808,\n",
       " 'min_child_samples': 229,\n",
       " 'min_child_weight': 7.367478870340577,\n",
       " 'subsample': 0.39095982111246597,\n",
       " 'colsample_bylevel': 0.34924153428375315,\n",
       " 'reg_alpha': 0.05387841564588599,\n",
       " 'reg_lambda': 0.06614746132682563}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_params_dict['z_scratch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastry_params = y_params_dict['pastry']\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = y_params_dict['z_scratch']\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = y_params_dict['k_scatch']\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = y_params_dict['stains']\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = y_params_dict['dirtiness']\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = y_params_dict['bumps']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = y_params_dict['other_faults']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.556846</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>0.150386</td>\n",
       "      <td>0.309808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.148470</td>\n",
       "      <td>0.137887</td>\n",
       "      <td>0.315844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.472201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.125359</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.336195</td>\n",
       "      <td>0.433519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.631552</td>\n",
       "      <td>0.375618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Pastry  Z_Scratch  K_Scatch    Stains  Dirtiness     Bumps  \\\n",
       "0  19219  0.556846   0.001224  0.003118  0.000023   0.016610  0.150386   \n",
       "1  19220  0.277344   0.013506  0.004721  0.000044   0.148470  0.137887   \n",
       "2  19221  0.001745   0.020020  0.052210  0.000121   0.001968  0.317900   \n",
       "3  19222  0.125359   0.001467  0.000452  0.000926   0.005287  0.336195   \n",
       "4  19223  0.002675   0.001682  0.000493  0.001442   0.006612  0.631552   \n",
       "\n",
       "   Other_Faults  \n",
       "0      0.309808  \n",
       "1      0.315844  \n",
       "2      0.472201  \n",
       "3      0.433519  \n",
       "4      0.375618  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715945082358949\n"
     ]
    }
   ],
   "source": [
    "ts = 0\n",
    "for yn,score in y_scores:\n",
    "    ts += score\n",
    "    \n",
    "print(ts/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715724463430068\n",
      "0.8716229666454796\n",
      "0.8711610211743859\n",
      "0.8718911456624303\n",
      "0.8716650442140532\n",
      "0.871617374898657\n",
      "0.8716315587132517\n"
     ]
    }
   ],
   "source": [
    "for yn,score in y_scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "pastry_params = {'n_estimators': 280,\n",
    " 'max_depth': 9,\n",
    " 'num_leaves': 18,\n",
    " 'learning_rate': 0.02148602951813924,\n",
    " 'min_child_samples': 341,\n",
    " 'min_child_weight': 6.361004402846124,\n",
    " 'subsample': 0.49585801139053814,\n",
    " 'colsample_bylevel': 0.35930633871573076,\n",
    " 'reg_alpha': 0.06447122051496705,\n",
    " 'reg_lambda': 0.016497887759421646}\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = {'n_estimators': 296,\n",
    " 'max_depth': 3,\n",
    " 'num_leaves': 74,\n",
    " 'learning_rate': 0.03879534308586422,\n",
    " 'min_child_samples': 298,\n",
    " 'min_child_weight': 2.4215929637347218,\n",
    " 'subsample': 0.47753292687280846,\n",
    " 'colsample_bylevel': 0.35906419523398436,\n",
    " 'reg_alpha': 0.057670762264904175,\n",
    " 'reg_lambda': 0.0427161308925542}\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = {'n_estimators': 271,\n",
    " 'max_depth': 29,\n",
    " 'num_leaves': 118,\n",
    " 'learning_rate': 0.02560845874325205,\n",
    " 'min_child_samples': 449,\n",
    " 'min_child_weight': 1.802873155395419,\n",
    " 'subsample': 0.7902749625886126,\n",
    " 'colsample_bylevel': 0.3433292920431201,\n",
    " 'reg_alpha': 0.047379430530416024,\n",
    " 'reg_lambda': 0.010007517965380167}\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = {'n_estimators': 266,\n",
    " 'max_depth': 5,\n",
    " 'num_leaves': 75,\n",
    " 'learning_rate': 0.027151102431374634,\n",
    " 'min_child_samples': 170,\n",
    " 'min_child_weight': 1.024782187730875,\n",
    " 'subsample': 0.5803990695479041,\n",
    " 'colsample_bylevel': 0.6394813204481101,\n",
    " 'reg_alpha': 0.09477440109735585,\n",
    " 'reg_lambda': 0.05246070547701958}\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = {'n_estimators': 100,\n",
    " 'max_depth': 13,\n",
    " 'num_leaves': 62,\n",
    " 'learning_rate': 0.04095550709994935,\n",
    " 'min_child_samples': 331,\n",
    " 'min_child_weight': 0.1953843881250878,\n",
    " 'subsample': 0.4674944721594767,\n",
    " 'colsample_bylevel': 0.33072889947558426,\n",
    " 'reg_alpha': 0.07067954909592045,\n",
    " 'reg_lambda': 0.0017098736746246962}\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = y_params_dict['bumps']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = y_params_dict['other_faults']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m5_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218194736189717"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8721124548680992 + 0.9613490481775984 + 0.9860986294660549 + 0.9931795666268013 + 0.8967476825823397 + 0.871617374898657 + 0.8716315587132517)/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
