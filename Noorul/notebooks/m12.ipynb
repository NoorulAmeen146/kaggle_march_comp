{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import catboost\n",
    "import re\n",
    "import optuna\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import main\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer,\n",
    "                                   OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "col_names = []\n",
    "with open('../data/Faults27x7_var','r') as f:\n",
    "    for line in f:\n",
    "        col_names.append(line.strip())\n",
    "        \n",
    "train_org = pd.read_csv('../data/train.csv')\n",
    "test_org = pd.read_csv('../data/test.csv')\n",
    "org_data = pd.read_csv('../data/Faults.NNA', delimiter='\\s', engine='python', names=col_names)\n",
    "\n",
    "X = train_org.drop(['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps','Other_Faults'], axis=1)\n",
    "pastry = train_org['Pastry'].copy()\n",
    "z_scratch = train_org['Z_Scratch'].copy()\n",
    "k_scatch = train_org['K_Scatch'].copy()\n",
    "stains = train_org['Stains'].copy()\n",
    "dirtiness = train_org['Dirtiness'].copy()\n",
    "bumps = train_org['Bumps'].copy()\n",
    "other_faults = train_org['Other_Faults'].copy()\n",
    "\n",
    "ys = [pastry, z_scratch, k_scatch, stains, dirtiness, bumps, other_faults]\n",
    "y_names = ['pastry', 'z_scratch', 'k_scatch', 'stains', 'dirtiness', 'bumps', 'other_faults']\n",
    "\n",
    "class KMeansTransformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=0)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        self.kmeans.fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        labels = self.kmeans.predict(X)\n",
    "        return np.c_[X, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,y_name in zip(ys,y_names):\n",
    "    \n",
    "    print(f'trial: {y_name}')\n",
    "    \n",
    "    def objective_lgb(trial):\n",
    "    \n",
    "        cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        params = dict(\n",
    "            n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "            max_depth = trial.suggest_int('max_depth',2,64),\n",
    "            num_leaves = trial.suggest_int('num_leaves',2,128),\n",
    "            learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "            min_child_samples = trial.suggest_int('min_child_samples',2,500),\n",
    "            min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "            subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "            colsample_bytree = trial.suggest_float('colsample_bylevel',0.33,0.7),\n",
    "            reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "            reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "        )\n",
    "        \n",
    "        lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "        \n",
    "        pipe = Pipeline(\n",
    "            steps = [\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', lgbc)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "        return score\n",
    "    \n",
    "    study_lgb = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "    \n",
    "    best_params = study_lgb.best_params\n",
    "    y_params_dict[y_name] = best_params\n",
    "    \n",
    "    best_score = study_lgb.best_value\n",
    "    y_scores[y_name] = best_score\n",
    "    \n",
    "    time.sleep(2)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'lgbc vanilla with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = {}\n",
    "    for i in [4,5,7]:\n",
    "        if i ==1:\n",
    "            continue\n",
    "        y_params_dict[y_nm][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}\n",
    "for yns in y_names:\n",
    "    y_scores[yns] = {}\n",
    "    for n in [4,5,7]:\n",
    "        y_scores[yns][n] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate([4,5,7]):\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_lgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(2)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'lgbc experiment with varying n_clusters(4,5,7) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate([2,3]):\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_lgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            lgbc = lgb.LGBMClassifier(random_state= 0, objective='binary', verbose=-1,**params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', lgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_lgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(2)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'lgbc experiment with varying n_clusters(2,3) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/12_Mar_06_54_23.json','r') as file:\n",
    "    rd = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': 0.8719188684326825,\n",
       " 'z_scratch': 0.9613491379485734,\n",
       " 'k_scatch': 0.9861826041592829,\n",
       " 'stains': 0.9929364569004854,\n",
       " 'dirtiness': 0.8984424720696227,\n",
       " 'bumps': 0.8117495758112815,\n",
       " 'other_faults': 0.7091654213801943}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "final_score: 0.8902492195288746\n"
     ]
    }
   ],
   "source": [
    "fs = 0\n",
    "for key in rd.keys():\n",
    "    \n",
    "    fs += rd[key]\n",
    "    \n",
    "print(f'\\nfinal_score: {fs/7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/12_Mar_06_54_19.json','r') as file:\n",
    "    pd = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastry_params = pd['pastry']\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = pd['z_scratch']\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = pd['k_scatch']\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = pd['stains']\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = pd['dirtiness']\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = pd['bumps']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = pd['other_faults']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.552399</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.161874</td>\n",
       "      <td>0.340980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.299751</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.182748</td>\n",
       "      <td>0.171236</td>\n",
       "      <td>0.326938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.048136</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.297688</td>\n",
       "      <td>0.477086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.155694</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.377820</td>\n",
       "      <td>0.437101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.629521</td>\n",
       "      <td>0.399463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Pastry  Z_Scratch  K_Scatch    Stains  Dirtiness     Bumps  \\\n",
       "0  19219  0.552399   0.001176  0.002196  0.000092   0.010662  0.161874   \n",
       "1  19220  0.299751   0.011878  0.000943  0.000153   0.182748  0.171236   \n",
       "2  19221  0.002521   0.048136  0.037964  0.000734   0.005654  0.297688   \n",
       "3  19222  0.155694   0.001702  0.000196  0.000986   0.011084  0.377820   \n",
       "4  19223  0.003227   0.002123  0.000201  0.004021   0.007892  0.629521   \n",
       "\n",
       "   Other_Faults  \n",
       "0      0.340980  \n",
       "1      0.326938  \n",
       "2      0.477086  \n",
       "3      0.437101  \n",
       "4      0.399463  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m12_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires to load necessary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastry, n_clusters:4, score:0.8720316370550407\n",
      "z_scratch, n_clusters:5, score:0.9614436879626707\n",
      "k_scatch, n_clusters:7, score:0.9860581348821281\n",
      "stains, n_clusters:7, score:0.9929668328934336\n",
      "dirtiness, n_clusters:2, score:0.8964052730066661\n",
      "bumps, n_clusters:2, score:0.8117091433569099\n",
      "other_faults, n_clusters:2, score:0.7092812461693652\n",
      "\n",
      "final_score: 0.8899851364751734\n"
     ]
    }
   ],
   "source": [
    "fs = 0\n",
    "for key in rd.keys():\n",
    "    val = 0\n",
    "    nc = 0\n",
    "    for sub_key in rd[key].keys():\n",
    "        if rd[key][sub_key] > val:\n",
    "            val = rd[key][sub_key]\n",
    "            nc = int(sub_key)\n",
    "    fs += val\n",
    "    print(f'{key}, n_clusters:{nc}, score:{val}')\n",
    "    \n",
    "print(f'\\nfinal_score: {fs/7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/12_Mar_19_59_03.json','r') as file:\n",
    "    pd = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastry_params = pd['pastry']['4']\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=4)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = pd['z_scratch']['5']\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = pd['k_scatch']['7']\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('KMeans', KMeansTransformer(n_clusters=7)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = pd['stains']['7']\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(7)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = pd['dirtiness']['2']\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(2)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = pd['bumps']['2']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(2)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = pd['other_faults']['2']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(2)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.481416</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.154150</td>\n",
       "      <td>0.317981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.133880</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>0.321465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.040209</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.322317</td>\n",
       "      <td>0.489446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.147363</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.359708</td>\n",
       "      <td>0.432672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.614681</td>\n",
       "      <td>0.390724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Pastry  Z_Scratch  K_Scatch    Stains  Dirtiness     Bumps  \\\n",
       "0  19219  0.481416   0.000935  0.008414  0.000023   0.020232  0.154150   \n",
       "1  19220  0.374900   0.019936  0.006365  0.000080   0.133880  0.160983   \n",
       "2  19221  0.001870   0.047187  0.040209  0.000177   0.005786  0.322317   \n",
       "3  19222  0.147363   0.001075  0.001337  0.001100   0.012126  0.359708   \n",
       "4  19223  0.003465   0.001280  0.002112  0.003120   0.007647  0.614681   \n",
       "\n",
       "   Other_Faults  \n",
       "0      0.317981  \n",
       "1      0.321465  \n",
       "2      0.489446  \n",
       "3      0.432672  \n",
       "4      0.390724  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "pastry_params = {'n_estimators': 280,\n",
    " 'max_depth': 9,\n",
    " 'num_leaves': 18,\n",
    " 'learning_rate': 0.02148602951813924,\n",
    " 'min_child_samples': 341,\n",
    " 'min_child_weight': 6.361004402846124,\n",
    " 'subsample': 0.49585801139053814,\n",
    " 'colsample_bylevel': 0.35930633871573076,\n",
    " 'reg_alpha': 0.06447122051496705,\n",
    " 'reg_lambda': 0.016497887759421646}\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = {'n_estimators': 296,\n",
    " 'max_depth': 3,\n",
    " 'num_leaves': 74,\n",
    " 'learning_rate': 0.03879534308586422,\n",
    " 'min_child_samples': 298,\n",
    " 'min_child_weight': 2.4215929637347218,\n",
    " 'subsample': 0.47753292687280846,\n",
    " 'colsample_bylevel': 0.35906419523398436,\n",
    " 'reg_alpha': 0.057670762264904175,\n",
    " 'reg_lambda': 0.0427161308925542}\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = {'n_estimators': 271,\n",
    " 'max_depth': 29,\n",
    " 'num_leaves': 118,\n",
    " 'learning_rate': 0.02560845874325205,\n",
    " 'min_child_samples': 449,\n",
    " 'min_child_weight': 1.802873155395419,\n",
    " 'subsample': 0.7902749625886126,\n",
    " 'colsample_bylevel': 0.3433292920431201,\n",
    " 'reg_alpha': 0.047379430530416024,\n",
    " 'reg_lambda': 0.010007517965380167}\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = {'n_estimators': 266,\n",
    " 'max_depth': 5,\n",
    " 'num_leaves': 75,\n",
    " 'learning_rate': 0.027151102431374634,\n",
    " 'min_child_samples': 170,\n",
    " 'min_child_weight': 1.024782187730875,\n",
    " 'subsample': 0.5803990695479041,\n",
    " 'colsample_bylevel': 0.6394813204481101,\n",
    " 'reg_alpha': 0.09477440109735585,\n",
    " 'reg_lambda': 0.05246070547701958}\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = {'n_estimators': 100,\n",
    " 'max_depth': 13,\n",
    " 'num_leaves': 62,\n",
    " 'learning_rate': 0.04095550709994935,\n",
    " 'min_child_samples': 331,\n",
    " 'min_child_weight': 0.1953843881250878,\n",
    " 'subsample': 0.4674944721594767,\n",
    " 'colsample_bylevel': 0.33072889947558426,\n",
    " 'reg_alpha': 0.07067954909592045,\n",
    " 'reg_lambda': 0.0017098736746246962}\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans', KMeansTransformer(n_clusters=5)),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = y_params_dict['bumps']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = y_params_dict['other_faults']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', lgb.LGBMClassifier(random_state= 0, objective='binary', verbose = -1,**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m5_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218194736189717"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8721124548680992 + 0.9613490481775984 + 0.9860986294660549 + 0.9931795666268013 + 0.8967476825823397 + 0.871617374898657 + 0.8716315587132517)/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
