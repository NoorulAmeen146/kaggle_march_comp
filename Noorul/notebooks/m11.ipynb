{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import catboost\n",
    "import re\n",
    "import optuna\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import main\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer,\n",
    "                                   OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "col_names = []\n",
    "with open('../data/Faults27x7_var','r') as f:\n",
    "    for line in f:\n",
    "        col_names.append(line.strip())\n",
    "        \n",
    "train_org = pd.read_csv('../data/train.csv')\n",
    "test_org = pd.read_csv('../data/test.csv')\n",
    "org_data = pd.read_csv(r'../data/Faults.NNA', delimiter='\\\\s+', names=col_names)\n",
    "\n",
    "X = train_org.drop(['id','Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps','Other_Faults'], axis=1)\n",
    "pastry = train_org['Pastry'].copy()\n",
    "z_scratch = train_org['Z_Scratch'].copy()\n",
    "k_scatch = train_org['K_Scatch'].copy()\n",
    "stains = train_org['Stains'].copy()\n",
    "dirtiness = train_org['Dirtiness'].copy()\n",
    "bumps = train_org['Bumps'].copy()\n",
    "other_faults = train_org['Other_Faults'].copy()\n",
    "\n",
    "ys = [pastry, z_scratch, k_scatch, stains, dirtiness, bumps, other_faults]\n",
    "y_names = ['pastry', 'z_scratch', 'k_scatch', 'stains', 'dirtiness', 'bumps', 'other_faults']\n",
    "\n",
    "class KMeansTransformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=0)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        self.kmeans.fit(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        labels = self.kmeans.predict(X)\n",
    "        return np.c_[X, labels]\n",
    "    \n",
    "class PCA_Transformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=self.n_components, random_state=0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.pca.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        cols = self.pca.transform(X)\n",
    "        return np.c_[X, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_clusters(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = {}\n",
    "    for i in [2,3]:\n",
    "        if i ==1:\n",
    "            continue\n",
    "        y_params_dict[y_nm][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': {2: None, 3: None},\n",
       " 'z_scratch': {2: None, 3: None},\n",
       " 'k_scatch': {2: None, 3: None},\n",
       " 'stains': {2: None, 3: None},\n",
       " 'dirtiness': {2: None, 3: None},\n",
       " 'bumps': {2: None, 3: None},\n",
       " 'other_faults': {2: None, 3: None}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}\n",
    "for yns in y_names:\n",
    "    y_scores[yns] = {}\n",
    "    for n in [2,3]:\n",
    "        y_scores[yns][n] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for y,yn in zip(ys,y_names):\n",
    "    for n,i in enumerate([2,3]):\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_xgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            xgbc = xgb.XGBClassifier(random_state= 0, objective='binary:logistic', **params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', xgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_xgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(5)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'xgbc experiment with varying n_clusters(2,3) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/10_Mar_17_05_48.json','r') as file:\n",
    "    res_dict_1 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/10_Mar_21_53_08.json','r') as file:\n",
    "    res_dict_2 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_14_11_47.json','r') as file:\n",
    "    res_dict_3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in res_dict_1.keys():\n",
    "    for sub_key,value in res_dict_3[key].items():\n",
    "        res_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in res_dict_1.keys():\n",
    "    for sub_key,value in res_dict_2[key].items():\n",
    "        res_dict_1[key][sub_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': {'4': 0.87316342526509,\n",
       "  '5': 0.8723859380558331,\n",
       "  '7': 0.8718382015595232,\n",
       "  '2': 0.872368673985698,\n",
       "  '3': 0.8720512972515024,\n",
       "  '8': 0.8718805289258797},\n",
       " 'z_scratch': {'4': 0.9613890153078358,\n",
       "  '5': 0.9615976308667188,\n",
       "  '7': 0.9612414577306605,\n",
       "  '2': 0.9614434244435696,\n",
       "  '3': 0.9612456383409917,\n",
       "  '8': 0.9610154842078904},\n",
       " 'k_scatch': {'4': 0.9860858535887431,\n",
       "  '5': 0.9860992844372543,\n",
       "  '7': 0.9861330613828573,\n",
       "  '2': 0.9861501596835595,\n",
       "  '3': 0.9860706017688351,\n",
       "  '8': 0.9861393751670559},\n",
       " 'stains': {'4': 0.9929431745506421,\n",
       "  '5': 0.9928315474707956,\n",
       "  '7': 0.992771472558994,\n",
       "  '2': 0.9927847507110557,\n",
       "  '3': 0.992721780865689,\n",
       "  '8': 0.9927694558697684},\n",
       " 'dirtiness': {'4': 0.896228905082517,\n",
       "  '5': 0.8965788929674312,\n",
       "  '7': 0.8962361142448083,\n",
       "  '2': 0.8966721070524626,\n",
       "  '3': 0.8973262934703824,\n",
       "  '8': 0.8963041608221399},\n",
       " 'bumps': {'4': 0.8112450626879427,\n",
       "  '5': 0.8113776963214827,\n",
       "  '7': 0.8117126719857447,\n",
       "  '2': 0.8115072931400666,\n",
       "  '3': 0.8117351598399493,\n",
       "  '8': 0.8117011880090118},\n",
       " 'other_faults': {'4': 0.709829411188906,\n",
       "  '5': 0.7101061980300873,\n",
       "  '7': 0.709844412440002,\n",
       "  '2': 0.7099461997981216,\n",
       "  '3': 0.7103388093664101,\n",
       "  '8': 0.7097946557491299}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastry, n_cluster:4, score: 0.87316342526509\n",
      "z_scratch, n_cluster:5, score: 0.9615976308667188\n",
      "k_scatch, n_cluster:2, score: 0.9861501596835595\n",
      "stains, n_cluster:4, score: 0.9929431745506421\n",
      "dirtiness, n_cluster:3, score: 0.8973262934703824\n",
      "bumps, n_cluster:3, score: 0.8117351598399493\n",
      "other_faults, n_cluster:3, score: 0.7103388093664101\n",
      "\n",
      "final_score: 0.890464950434679\n"
     ]
    }
   ],
   "source": [
    "fres = 0\n",
    "for key in res_dict_1.keys():\n",
    "    res = 0\n",
    "    n_c = 0\n",
    "    for sub_key in res_dict_1[key].keys():\n",
    "        if res_dict_1[key][sub_key] > res:\n",
    "            res = res_dict_1[key][sub_key]\n",
    "            n_c = int(sub_key)\n",
    "    \n",
    "    fres += res        \n",
    "    print(f'{key}, n_cluster:{n_c}, score: {res}')\n",
    "print(f'\\nfinal_score: {fres/7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/10_Mar_17_05_44.json','r') as file:\n",
    "    prms_dict_1 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/10_Mar_21_53_04.json','r') as file:\n",
    "    prms_dict_2 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_14_11_43.json','r') as file:\n",
    "    prms_dict_3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in prms_dict_1.keys():\n",
    "    for sub_key,value in prms_dict_3[key].items():\n",
    "        prms_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in prms_dict_1.keys():\n",
    "    for sub_key,value in prms_dict_2[key].items():\n",
    "        prms_dict_1[key][sub_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastry_params = prms_dict_1['pastry']['4']\n",
    "\n",
    "pastry_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=4)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**pastry_params))\n",
    "    ]\n",
    ")\n",
    "pastry_m.fit(X,pastry)\n",
    "pastry_pred = pastry_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scratch_params = prms_dict_1['z_scratch']['5']\n",
    "\n",
    "z_scratch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=5)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic', **z_scratch_params))\n",
    "    ]\n",
    ")\n",
    "z_scratch_m.fit(X,z_scratch)\n",
    "z_scratch_pred = z_scratch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scatch_params = prms_dict_1['k_scatch']['2']\n",
    "\n",
    "k_scatch_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=7)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**k_scatch_params))\n",
    "    ]\n",
    ")\n",
    "k_scatch_m.fit(X,k_scatch)\n",
    "k_scatch_pred = k_scatch_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains_params = prms_dict_1['stains']['4']\n",
    "\n",
    "stains_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=4)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**stains_params))\n",
    "    ]\n",
    ")\n",
    "stains_m.fit(X,stains)\n",
    "stains_pred = stains_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtiness_params = prms_dict_1['dirtiness']['3']\n",
    "\n",
    "dirtiness_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=5)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**dirtiness_params))\n",
    "    ]\n",
    ")\n",
    "dirtiness_m.fit(X,dirtiness)\n",
    "dirtiness_pred = dirtiness_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumps_params = prms_dict_1['bumps']['3']\n",
    "\n",
    "bumps_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=7)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**bumps_params))\n",
    "    ]\n",
    ")\n",
    "bumps_m.fit(X,bumps)\n",
    "bumps_pred = bumps_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_faults_params = prms_dict_1['other_faults']['3']\n",
    "\n",
    "other_faults_m = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kmeans',KMeansTransformer(n_clusters=5)),\n",
    "        ('model', xgb.XGBClassifier(random_state= 0, objective='binary:logistic',**other_faults_params))\n",
    "    ]\n",
    ")\n",
    "other_faults_m.fit(X,other_faults)\n",
    "other_faults_pred = other_faults_m.predict_proba(test_org.drop(['id'], axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':test_org['id'].copy(), 'Pastry':pastry_pred, 'Z_Scratch':z_scratch_pred, 'K_Scatch':k_scatch_pred,\n",
    "                    'Stains':stains_pred, 'Dirtiness':dirtiness_pred, 'Bumps':bumps_pred, 'Other_Faults':other_faults_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.505621</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.158008</td>\n",
       "      <td>0.322089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.250375</td>\n",
       "      <td>0.022483</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.136549</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.329280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.049589</td>\n",
       "      <td>0.041254</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.282640</td>\n",
       "      <td>0.481709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.159196</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.360755</td>\n",
       "      <td>0.431707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.580453</td>\n",
       "      <td>0.389343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Pastry  Z_Scratch  K_Scatch    Stains  Dirtiness     Bumps  \\\n",
       "0  19219  0.505621   0.000767  0.005441  0.000113   0.014624  0.158008   \n",
       "1  19220  0.250375   0.022483  0.006838  0.000227   0.136549  0.143548   \n",
       "2  19221  0.001104   0.049589  0.041254  0.000598   0.004451  0.282640   \n",
       "3  19222  0.159196   0.001625  0.000737  0.001228   0.006225  0.360755   \n",
       "4  19223  0.002299   0.001828  0.001170  0.008662   0.006621  0.580453   \n",
       "\n",
       "   Other_Faults  \n",
       "0      0.322089  \n",
       "1      0.329280  \n",
       "2      0.481709  \n",
       "3      0.431707  \n",
       "4      0.389343  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0461770000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.505621+0.000767+0.005444+0.000113+0.019555+0.167881+0.346796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/m11.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_clusters(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params_dict = {}\n",
    "for y_nm in y_names:\n",
    "    y_params_dict[y_nm] = {}\n",
    "    for i in [6]:\n",
    "        if i ==1:\n",
    "            continue\n",
    "        y_params_dict[y_nm][i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pastry': {6: None},\n",
       " 'z_scratch': {6: None},\n",
       " 'k_scatch': {6: None},\n",
       " 'stains': {6: None},\n",
       " 'dirtiness': {6: None},\n",
       " 'bumps': {6: None},\n",
       " 'other_faults': {6: None}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = {}\n",
    "for yns in y_names:\n",
    "    y_scores[yns] = {}\n",
    "    for n in [6]:\n",
    "        y_scores[yns][n] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for y,yn in zip(ys,y_names):\n",
    "    for i in [6]:\n",
    "        \n",
    "        print(f'trial: {yn}(n_cluster={i})')\n",
    "        \n",
    "        def objective_xgb(trial):\n",
    "    \n",
    "            cvo = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            params = dict(\n",
    "                n_estimators = trial.suggest_int('n_estimators',100,500),\n",
    "                max_depth = trial.suggest_int('max_depth',2,64),\n",
    "                max_leaves = trial.suggest_int('max_leaves',2,128),\n",
    "                learning_rate = trial.suggest_float('learning_rate',0.001,0.3),\n",
    "                gamma = trial.suggest_float('gamma',0.001,10),\n",
    "                min_child_weight = trial.suggest_float('min_child_weight', 0.01,10),\n",
    "                subsample = trial.suggest_float('subsample', 0.33,0.85),\n",
    "                colsample_bytree = trial.suggest_float('colsample_bytree',0.33,0.7),\n",
    "                reg_alpha=trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "                reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.1)\n",
    "            )\n",
    "            \n",
    "            xgbc = xgb.XGBClassifier(random_state= 0, objective='binary:logistic', **params)\n",
    "            \n",
    "            pipe = Pipeline(\n",
    "                steps = [\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('kmeans', KMeansTransformer(n_clusters=i)),\n",
    "                    ('model', xgbc)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            score = np.mean(cross_val_score(pipe, X,y, scoring='roc_auc', cv= cvo))\n",
    "            return score\n",
    "        \n",
    "        study_lgb = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        study_lgb.optimize(objective_xgb, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "        \n",
    "        best_params = study_lgb.best_params\n",
    "        y_params_dict[yn][i] = best_params\n",
    "        \n",
    "        best_score = study_lgb.best_value\n",
    "        y_scores[yn][i] = best_score\n",
    "        \n",
    "        time.sleep(5)\n",
    "        clear_output()\n",
    "        \n",
    "description = 'xgbc experiment with varying n_clusters(6) along with hpt'\n",
    "main.saver(y_params_dict,y_scores,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/10_Mar_17_05_44.json','r') as file:\n",
    "    par_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/10_Mar_17_05_44.json','r') as file:\n",
    "    prms_dict_1 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/10_Mar_21_53_04.json','r') as file:\n",
    "    prms_dict_2 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_14_11_43.json','r') as file:\n",
    "    prms_dict_3 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_20_57_46.json','r') as file:\n",
    "    prms_dict_4 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in prms_dict_1.keys():\n",
    "    for sub_key,value in prms_dict_3[key].items():\n",
    "        prms_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in prms_dict_1.keys():\n",
    "    for sub_key,value in prms_dict_2[key].items():\n",
    "        prms_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in prms_dict_1.keys():\n",
    "    for sub_key,value in prms_dict_4[key].items():\n",
    "        prms_dict_1[key][sub_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/n_clusters_params.json','w') as f:\n",
    "    json.dump(prms_dict_1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/10_Mar_17_05_48.json','r') as file:\n",
    "    res_dict_1 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/10_Mar_21_53_08.json','r') as file:\n",
    "    res_dict_2 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_14_11_47.json','r') as file:\n",
    "    res_dict_3 = json.load(file)\n",
    "    \n",
    "with open('../../artifacts/11_Mar_20_57_50.json','r') as file:\n",
    "    res_dict_4 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in res_dict_1.keys():\n",
    "    for sub_key,value in res_dict_3[key].items():\n",
    "        res_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in res_dict_1.keys():\n",
    "    for sub_key,value in res_dict_2[key].items():\n",
    "        res_dict_1[key][sub_key] = value\n",
    "        \n",
    "for key in res_dict_1.keys():\n",
    "    for sub_key,value in res_dict_4[key].items():\n",
    "        res_dict_1[key][sub_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../artifacts/n_clusters_results.json','w') as f:\n",
    "    json.dump(res_dict_1,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
